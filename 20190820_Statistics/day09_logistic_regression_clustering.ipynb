{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from statsmodels.formula.api import glm\n",
    "from statsmodels.genmod.families.family import Binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "burnout = pandas.read_csv('burnout.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>burnout</th>\n",
       "      <th>loc</th>\n",
       "      <th>cope</th>\n",
       "      <th>teaching</th>\n",
       "      <th>research</th>\n",
       "      <th>pastoral</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Burnt Out</td>\n",
       "      <td>7.647059</td>\n",
       "      <td>9.160305</td>\n",
       "      <td>32.727273</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>31.481481</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Burnt Out</td>\n",
       "      <td>6.470588</td>\n",
       "      <td>12.977099</td>\n",
       "      <td>52.727273</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>68.518519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Burnt Out</td>\n",
       "      <td>8.823529</td>\n",
       "      <td>9.160305</td>\n",
       "      <td>49.090909</td>\n",
       "      <td>60.416667</td>\n",
       "      <td>53.703704</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Burnt Out</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>9.160305</td>\n",
       "      <td>52.727273</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not Burnt Out</td>\n",
       "      <td>6.470588</td>\n",
       "      <td>19.083969</td>\n",
       "      <td>43.636364</td>\n",
       "      <td>79.166667</td>\n",
       "      <td>40.740741</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         burnout        loc       cope   teaching   research   pastoral  y\n",
       "0  Not Burnt Out   7.647059   9.160305  32.727273  87.500000  31.481481  0\n",
       "1  Not Burnt Out   6.470588  12.977099  52.727273  66.666667  68.518519  0\n",
       "2  Not Burnt Out   8.823529   9.160305  49.090909  60.416667  53.703704  0\n",
       "3  Not Burnt Out  20.000000   9.160305  52.727273  62.500000  50.000000  0\n",
       "4  Not Burnt Out   6.470588  19.083969  43.636364  79.166667  40.740741  0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burnout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "burnout['y'] = burnout['burnout'].replace({'Burnt Out': 1, 'Not Burnt Out': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = glm('y ~ teaching * cope', burnout, family=Binomial()).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>y</td>        <th>  No. Observations:  </th>  <td>   467</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   463</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>       <td>Binomial</td>     <th>  Df Model:          </th>  <td>     3</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>        <td>logit</td>      <th>  Scale:             </th> <td>  1.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -177.25</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>           <td>Tue, 01 Oct 2019</td> <th>  Deviance:          </th> <td>  354.51</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>               <td>17:29:17</td>     <th>  Pearson chi2:      </th>  <td>  357.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>6</td>        <th>  Covariance Type:   </th> <td>nonrobust</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>     <td>   -8.4114</td> <td>    1.359</td> <td>   -6.187</td> <td> 0.000</td> <td>  -11.076</td> <td>   -5.747</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>teaching</th>      <td>    0.0684</td> <td>    0.023</td> <td>    2.987</td> <td> 0.003</td> <td>    0.024</td> <td>    0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cope</th>          <td>    0.3287</td> <td>    0.042</td> <td>    7.736</td> <td> 0.000</td> <td>    0.245</td> <td>    0.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>teaching:cope</th> <td>   -0.0033</td> <td>    0.001</td> <td>   -5.802</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                  467\n",
       "Model:                            GLM   Df Residuals:                      463\n",
       "Model Family:                Binomial   Df Model:                            3\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -177.25\n",
       "Date:                Tue, 01 Oct 2019   Deviance:                       354.51\n",
       "Time:                        17:29:17   Pearson chi2:                     357.\n",
       "No. Iterations:                     6   Covariance Type:             nonrobust\n",
       "=================================================================================\n",
       "                    coef    std err          z      P>|z|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "Intercept        -8.4114      1.359     -6.187      0.000     -11.076      -5.747\n",
       "teaching          0.0684      0.023      2.987      0.003       0.024       0.113\n",
       "cope              0.3287      0.042      7.736      0.000       0.245       0.412\n",
       "teaching:cope    -0.0033      0.001     -5.802      0.000      -0.004      -0.002\n",
       "=================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399.09191057022167"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.aic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2363.440589787294"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.bic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = res.predict(burnout)  # 원칙적으로 새 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.015454\n",
       "1      0.057103\n",
       "2      0.028438\n",
       "3      0.032525\n",
       "4      0.128978\n",
       "5      0.071993\n",
       "6      0.064055\n",
       "7      0.017632\n",
       "8      0.021708\n",
       "9      0.068946\n",
       "10     0.059011\n",
       "11     0.055814\n",
       "12     0.522091\n",
       "13     0.020698\n",
       "14     0.153810\n",
       "15     0.032162\n",
       "16     0.013035\n",
       "17     0.024852\n",
       "18     0.018234\n",
       "19     0.056376\n",
       "20     0.048675\n",
       "21     0.032519\n",
       "22     0.053497\n",
       "23     0.136668\n",
       "24     0.283889\n",
       "25     0.086794\n",
       "26     0.028816\n",
       "27     0.581702\n",
       "28     0.036356\n",
       "29     0.029362\n",
       "         ...   \n",
       "437    0.844417\n",
       "438    0.865184\n",
       "439    0.686455\n",
       "440    0.795034\n",
       "441    0.678996\n",
       "442    0.742122\n",
       "443    0.784353\n",
       "444    0.682414\n",
       "445    0.211446\n",
       "446    0.768241\n",
       "447    0.460667\n",
       "448    0.631640\n",
       "449    0.802389\n",
       "450    0.907775\n",
       "451    0.673587\n",
       "452    0.944201\n",
       "453    0.666746\n",
       "454    0.867725\n",
       "455    0.626040\n",
       "456    0.990357\n",
       "457    0.487489\n",
       "458    0.920528\n",
       "459    0.971019\n",
       "460    0.975428\n",
       "461    0.894815\n",
       "462    0.694301\n",
       "463    0.933334\n",
       "464    0.506838\n",
       "465    0.772203\n",
       "466    0.342818\n",
       "Length: 467, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = numpy.where(prob > .5, 1, 0) # threshold = .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 혼돈행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[311,  37],\n",
       "       [ 58,  61]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true = burnout['y']\n",
    "confusion_matrix(true, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "                        예측\n",
    "                      Not Burnt Out(0)     Burnt Out(1)\n",
    "실제  Not Burnt Out           321              27  \n",
    "       Burnt Out               72              47\n",
    "        \n",
    "```   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정확도, 정밀도, 재현도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7965738758029979"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6224489795918368"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(true, pred, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5126050420168067"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(true, pred, pos_label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC 곡선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(true, prob, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fpr</th>\n",
       "      <th>tpr</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.990357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>0.990357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.959496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.949422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.075630</td>\n",
       "      <td>0.920528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.075630</td>\n",
       "      <td>0.916035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.092437</td>\n",
       "      <td>0.907775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.100840</td>\n",
       "      <td>0.894815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.867725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.005747</td>\n",
       "      <td>0.126050</td>\n",
       "      <td>0.865184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.126050</td>\n",
       "      <td>0.856464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.151261</td>\n",
       "      <td>0.844417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.151261</td>\n",
       "      <td>0.834141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.014368</td>\n",
       "      <td>0.168067</td>\n",
       "      <td>0.809298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.168067</td>\n",
       "      <td>0.804213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.184874</td>\n",
       "      <td>0.795034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.020115</td>\n",
       "      <td>0.193277</td>\n",
       "      <td>0.794254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.193277</td>\n",
       "      <td>0.788633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.201681</td>\n",
       "      <td>0.784353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.028736</td>\n",
       "      <td>0.201681</td>\n",
       "      <td>0.778998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.028736</td>\n",
       "      <td>0.210084</td>\n",
       "      <td>0.772203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.210084</td>\n",
       "      <td>0.768467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.743385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.742122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.048851</td>\n",
       "      <td>0.252101</td>\n",
       "      <td>0.694408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.260504</td>\n",
       "      <td>0.694301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.268908</td>\n",
       "      <td>0.689213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.686455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.319328</td>\n",
       "      <td>0.678996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.054598</td>\n",
       "      <td>0.336134</td>\n",
       "      <td>0.674637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.767241</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.036920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.772989</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.036440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.787356</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.036356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.793103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.798851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.804598</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.810345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.816092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.821839</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.827586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.836207</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.847701</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.030545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.856322</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.030210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.867816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.876437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.882184</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.887931</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.896552</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.902299</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.908046</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.913793</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.919540</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.925287</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.936782</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.945402</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.948276</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.959770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0.977011</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.982759</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fpr       tpr         t\n",
       "0    0.000000  0.000000  1.990357\n",
       "1    0.000000  0.008403  0.990357\n",
       "2    0.000000  0.033613  0.959496\n",
       "3    0.002874  0.033613  0.949422\n",
       "4    0.002874  0.075630  0.920528\n",
       "5    0.005747  0.075630  0.916035\n",
       "6    0.005747  0.092437  0.907775\n",
       "7    0.005747  0.100840  0.894815\n",
       "8    0.005747  0.117647  0.867725\n",
       "9    0.005747  0.126050  0.865184\n",
       "10   0.011494  0.126050  0.856464\n",
       "11   0.011494  0.151261  0.844417\n",
       "12   0.014368  0.151261  0.834141\n",
       "13   0.014368  0.168067  0.809298\n",
       "14   0.017241  0.168067  0.804213\n",
       "15   0.017241  0.184874  0.795034\n",
       "16   0.020115  0.193277  0.794254\n",
       "17   0.022989  0.193277  0.788633\n",
       "18   0.022989  0.201681  0.784353\n",
       "19   0.028736  0.201681  0.778998\n",
       "20   0.028736  0.210084  0.772203\n",
       "21   0.034483  0.210084  0.768467\n",
       "22   0.034483  0.235294  0.743385\n",
       "23   0.034483  0.252101  0.742122\n",
       "24   0.048851  0.252101  0.694408\n",
       "25   0.051724  0.260504  0.694301\n",
       "26   0.051724  0.268908  0.689213\n",
       "27   0.051724  0.294118  0.686455\n",
       "28   0.051724  0.319328  0.678996\n",
       "29   0.054598  0.336134  0.674637\n",
       "..        ...       ...       ...\n",
       "181  0.767241  1.000000  0.036920\n",
       "182  0.772989  1.000000  0.036440\n",
       "183  0.787356  1.000000  0.036356\n",
       "184  0.793103  1.000000  0.034998\n",
       "185  0.798851  1.000000  0.034775\n",
       "186  0.804598  1.000000  0.034310\n",
       "187  0.810345  1.000000  0.034237\n",
       "188  0.816092  1.000000  0.033172\n",
       "189  0.821839  1.000000  0.032525\n",
       "190  0.827586  1.000000  0.032375\n",
       "191  0.836207  1.000000  0.032162\n",
       "192  0.847701  1.000000  0.030545\n",
       "193  0.856322  1.000000  0.030210\n",
       "194  0.867816  1.000000  0.028740\n",
       "195  0.876437  1.000000  0.028438\n",
       "196  0.882184  1.000000  0.028231\n",
       "197  0.887931  1.000000  0.027008\n",
       "198  0.896552  1.000000  0.025017\n",
       "199  0.902299  1.000000  0.024852\n",
       "200  0.908046  1.000000  0.023897\n",
       "201  0.913793  1.000000  0.023387\n",
       "202  0.919540  1.000000  0.022205\n",
       "203  0.925287  1.000000  0.022050\n",
       "204  0.936782  1.000000  0.020565\n",
       "205  0.945402  1.000000  0.020285\n",
       "206  0.948276  1.000000  0.019735\n",
       "207  0.959770  1.000000  0.018234\n",
       "208  0.977011  1.000000  0.014572\n",
       "209  0.982759  1.000000  0.014435\n",
       "210  1.000000  1.000000  0.006955\n",
       "\n",
       "[211 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame({'fpr': fpr, 'tpr': tpr, 't': threshold}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22b5b7bdfd0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seaborn.lineplot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8856732348111658"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 클러스터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pandas.read_csv('wine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>MalicAcid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>AlcalinityOfAsh</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>TotalPhenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>NonflavanoidPhenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Alcohol  MalicAcid   Ash  AlcalinityOfAsh  Magnesium  TotalPhenols  \\\n",
       "0      1    14.23       1.71  2.43             15.6        127          2.80   \n",
       "1      1    13.20       1.78  2.14             11.2        100          2.65   \n",
       "2      1    13.16       2.36  2.67             18.6        101          2.80   \n",
       "3      1    14.37       1.95  2.50             16.8        113          3.85   \n",
       "4      1    13.24       2.59  2.87             21.0        118          2.80   \n",
       "\n",
       "   Flavanoids  NonflavanoidPhenols  Proanthocyanins  Color intensity   Hue  \\\n",
       "0        3.06                 0.28             2.29             5.64  1.04   \n",
       "1        2.76                 0.26             1.28             4.38  1.05   \n",
       "2        3.24                 0.30             2.81             5.68  1.03   \n",
       "3        3.49                 0.24             2.18             7.80  0.86   \n",
       "4        2.69                 0.39             1.82             4.32  1.04   \n",
       "\n",
       "     OD  Proline  \n",
       "0  3.92     1065  \n",
       "1  3.40     1050  \n",
       "2  3.17     1185  \n",
       "3  3.45     1480  \n",
       "4  2.93      735  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = wine.iloc[:, 1:]  # iloc: 번호로 위치를 지정, : 모든 행, 1: = 1열부터 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Min-Max Scaling: 최소값은 0, 최대값은 1이 되도록 조정\n",
    "- 표준화(Standardization): 모든 값에서 평균을 빼고, 표준편차로 나눠주는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>MalicAcid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>AlcalinityOfAsh</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>TotalPhenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>NonflavanoidPhenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  MalicAcid   Ash  AlcalinityOfAsh  Magnesium  TotalPhenols  \\\n",
       "0    14.23       1.71  2.43             15.6        127          2.80   \n",
       "1    13.20       1.78  2.14             11.2        100          2.65   \n",
       "2    13.16       2.36  2.67             18.6        101          2.80   \n",
       "3    14.37       1.95  2.50             16.8        113          3.85   \n",
       "4    13.24       2.59  2.87             21.0        118          2.80   \n",
       "\n",
       "   Flavanoids  NonflavanoidPhenols  Proanthocyanins  Color intensity   Hue  \\\n",
       "0        3.06                 0.28             2.29             5.64  1.04   \n",
       "1        2.76                 0.26             1.28             4.38  1.05   \n",
       "2        3.24                 0.30             2.81             5.68  1.03   \n",
       "3        3.49                 0.24             2.18             7.80  0.86   \n",
       "4        2.69                 0.39             1.82             4.32  1.04   \n",
       "\n",
       "     OD  Proline  \n",
       "0  3.92     1065  \n",
       "1  3.40     1050  \n",
       "2  3.17     1185  \n",
       "3  3.45     1480  \n",
       "4  2.93      735  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eupho\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eupho\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "x = scale.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.518613</td>\n",
       "      <td>-0.562250</td>\n",
       "      <td>0.232053</td>\n",
       "      <td>-1.169593</td>\n",
       "      <td>1.913905</td>\n",
       "      <td>0.808997</td>\n",
       "      <td>1.034819</td>\n",
       "      <td>-0.659563</td>\n",
       "      <td>1.224884</td>\n",
       "      <td>0.251717</td>\n",
       "      <td>0.362177</td>\n",
       "      <td>1.847920</td>\n",
       "      <td>1.013009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.246290</td>\n",
       "      <td>-0.499413</td>\n",
       "      <td>-0.827996</td>\n",
       "      <td>-2.490847</td>\n",
       "      <td>0.018145</td>\n",
       "      <td>0.568648</td>\n",
       "      <td>0.733629</td>\n",
       "      <td>-0.820719</td>\n",
       "      <td>-0.544721</td>\n",
       "      <td>-0.293321</td>\n",
       "      <td>0.406051</td>\n",
       "      <td>1.113449</td>\n",
       "      <td>0.965242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.196879</td>\n",
       "      <td>0.021231</td>\n",
       "      <td>1.109334</td>\n",
       "      <td>-0.268738</td>\n",
       "      <td>0.088358</td>\n",
       "      <td>0.808997</td>\n",
       "      <td>1.215533</td>\n",
       "      <td>-0.498407</td>\n",
       "      <td>2.135968</td>\n",
       "      <td>0.269020</td>\n",
       "      <td>0.318304</td>\n",
       "      <td>0.788587</td>\n",
       "      <td>1.395148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.691550</td>\n",
       "      <td>-0.346811</td>\n",
       "      <td>0.487926</td>\n",
       "      <td>-0.809251</td>\n",
       "      <td>0.930918</td>\n",
       "      <td>2.491446</td>\n",
       "      <td>1.466525</td>\n",
       "      <td>-0.981875</td>\n",
       "      <td>1.032155</td>\n",
       "      <td>1.186068</td>\n",
       "      <td>-0.427544</td>\n",
       "      <td>1.184071</td>\n",
       "      <td>2.334574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.295700</td>\n",
       "      <td>0.227694</td>\n",
       "      <td>1.840403</td>\n",
       "      <td>0.451946</td>\n",
       "      <td>1.281985</td>\n",
       "      <td>0.808997</td>\n",
       "      <td>0.663351</td>\n",
       "      <td>0.226796</td>\n",
       "      <td>0.401404</td>\n",
       "      <td>-0.319276</td>\n",
       "      <td>0.362177</td>\n",
       "      <td>0.449601</td>\n",
       "      <td>-0.037874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.481555</td>\n",
       "      <td>-0.517367</td>\n",
       "      <td>0.305159</td>\n",
       "      <td>-1.289707</td>\n",
       "      <td>0.860705</td>\n",
       "      <td>1.562093</td>\n",
       "      <td>1.366128</td>\n",
       "      <td>-0.176095</td>\n",
       "      <td>0.664217</td>\n",
       "      <td>0.731870</td>\n",
       "      <td>0.406051</td>\n",
       "      <td>0.336606</td>\n",
       "      <td>2.239039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.716255</td>\n",
       "      <td>-0.418624</td>\n",
       "      <td>0.305159</td>\n",
       "      <td>-1.469878</td>\n",
       "      <td>-0.262708</td>\n",
       "      <td>0.328298</td>\n",
       "      <td>0.492677</td>\n",
       "      <td>-0.498407</td>\n",
       "      <td>0.681738</td>\n",
       "      <td>0.083015</td>\n",
       "      <td>0.274431</td>\n",
       "      <td>1.367689</td>\n",
       "      <td>1.729520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.308617</td>\n",
       "      <td>-0.167278</td>\n",
       "      <td>0.890014</td>\n",
       "      <td>-0.569023</td>\n",
       "      <td>1.492625</td>\n",
       "      <td>0.488531</td>\n",
       "      <td>0.482637</td>\n",
       "      <td>-0.417829</td>\n",
       "      <td>-0.597284</td>\n",
       "      <td>-0.003499</td>\n",
       "      <td>0.449924</td>\n",
       "      <td>1.367689</td>\n",
       "      <td>1.745442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.259772</td>\n",
       "      <td>-0.625086</td>\n",
       "      <td>-0.718336</td>\n",
       "      <td>-1.650049</td>\n",
       "      <td>-0.192495</td>\n",
       "      <td>0.808997</td>\n",
       "      <td>0.954502</td>\n",
       "      <td>-0.578985</td>\n",
       "      <td>0.681738</td>\n",
       "      <td>0.061386</td>\n",
       "      <td>0.537671</td>\n",
       "      <td>0.336606</td>\n",
       "      <td>0.949319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.061565</td>\n",
       "      <td>-0.885409</td>\n",
       "      <td>-0.352802</td>\n",
       "      <td>-1.049479</td>\n",
       "      <td>-0.122282</td>\n",
       "      <td>1.097417</td>\n",
       "      <td>1.125176</td>\n",
       "      <td>-1.143031</td>\n",
       "      <td>0.453967</td>\n",
       "      <td>0.935177</td>\n",
       "      <td>0.230557</td>\n",
       "      <td>1.325316</td>\n",
       "      <td>0.949319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.358028</td>\n",
       "      <td>-0.158301</td>\n",
       "      <td>-0.243142</td>\n",
       "      <td>-0.448909</td>\n",
       "      <td>0.369212</td>\n",
       "      <td>1.049347</td>\n",
       "      <td>1.295850</td>\n",
       "      <td>-1.143031</td>\n",
       "      <td>1.382572</td>\n",
       "      <td>0.299300</td>\n",
       "      <td>1.283518</td>\n",
       "      <td>0.788587</td>\n",
       "      <td>2.430109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.382733</td>\n",
       "      <td>-0.768712</td>\n",
       "      <td>-0.170035</td>\n",
       "      <td>-0.809251</td>\n",
       "      <td>-0.332922</td>\n",
       "      <td>-0.152402</td>\n",
       "      <td>0.402320</td>\n",
       "      <td>-0.820719</td>\n",
       "      <td>-0.036617</td>\n",
       "      <td>-0.025128</td>\n",
       "      <td>0.932531</td>\n",
       "      <td>0.294232</td>\n",
       "      <td>1.697675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.925685</td>\n",
       "      <td>-0.544297</td>\n",
       "      <td>0.158946</td>\n",
       "      <td>-1.049479</td>\n",
       "      <td>-0.754202</td>\n",
       "      <td>0.488531</td>\n",
       "      <td>0.733629</td>\n",
       "      <td>-0.578985</td>\n",
       "      <td>0.383884</td>\n",
       "      <td>0.234414</td>\n",
       "      <td>0.844785</td>\n",
       "      <td>0.407228</td>\n",
       "      <td>1.825055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.160950</td>\n",
       "      <td>-0.544297</td>\n",
       "      <td>0.085839</td>\n",
       "      <td>-2.430790</td>\n",
       "      <td>-0.613775</td>\n",
       "      <td>1.289697</td>\n",
       "      <td>1.667318</td>\n",
       "      <td>0.549108</td>\n",
       "      <td>2.135968</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>1.283518</td>\n",
       "      <td>0.167113</td>\n",
       "      <td>1.283691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.703902</td>\n",
       "      <td>-0.418624</td>\n",
       "      <td>0.049285</td>\n",
       "      <td>-2.250619</td>\n",
       "      <td>0.158572</td>\n",
       "      <td>1.610163</td>\n",
       "      <td>1.617120</td>\n",
       "      <td>-0.578985</td>\n",
       "      <td>2.398780</td>\n",
       "      <td>1.056297</td>\n",
       "      <td>1.064151</td>\n",
       "      <td>0.548472</td>\n",
       "      <td>2.547935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.777454</td>\n",
       "      <td>-0.472483</td>\n",
       "      <td>1.218995</td>\n",
       "      <td>-0.689137</td>\n",
       "      <td>0.860705</td>\n",
       "      <td>0.889114</td>\n",
       "      <td>0.884224</td>\n",
       "      <td>-0.498407</td>\n",
       "      <td>-0.229346</td>\n",
       "      <td>0.969783</td>\n",
       "      <td>1.415139</td>\n",
       "      <td>0.378979</td>\n",
       "      <td>1.793210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.605081</td>\n",
       "      <td>-0.373741</td>\n",
       "      <td>1.292101</td>\n",
       "      <td>0.151661</td>\n",
       "      <td>1.422412</td>\n",
       "      <td>0.808997</td>\n",
       "      <td>1.115136</td>\n",
       "      <td>-0.256673</td>\n",
       "      <td>0.664217</td>\n",
       "      <td>0.493956</td>\n",
       "      <td>0.493797</td>\n",
       "      <td>0.054117</td>\n",
       "      <td>1.697675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.024507</td>\n",
       "      <td>-0.687923</td>\n",
       "      <td>0.926567</td>\n",
       "      <td>0.151661</td>\n",
       "      <td>1.071345</td>\n",
       "      <td>1.049347</td>\n",
       "      <td>1.376168</td>\n",
       "      <td>0.307374</td>\n",
       "      <td>0.226196</td>\n",
       "      <td>0.666984</td>\n",
       "      <td>0.757038</td>\n",
       "      <td>-0.058878</td>\n",
       "      <td>1.220001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.469202</td>\n",
       "      <td>-0.669969</td>\n",
       "      <td>0.414820</td>\n",
       "      <td>-0.899337</td>\n",
       "      <td>0.579852</td>\n",
       "      <td>1.610163</td>\n",
       "      <td>1.908270</td>\n",
       "      <td>-0.337251</td>\n",
       "      <td>0.471488</td>\n",
       "      <td>1.575381</td>\n",
       "      <td>1.195772</td>\n",
       "      <td>0.294232</td>\n",
       "      <td>2.971473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.789806</td>\n",
       "      <td>0.685502</td>\n",
       "      <td>0.707247</td>\n",
       "      <td>-1.289707</td>\n",
       "      <td>1.141558</td>\n",
       "      <td>0.648764</td>\n",
       "      <td>1.004700</td>\n",
       "      <td>-1.545922</td>\n",
       "      <td>0.121071</td>\n",
       "      <td>0.018129</td>\n",
       "      <td>0.011190</td>\n",
       "      <td>1.056952</td>\n",
       "      <td>0.312420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.308617</td>\n",
       "      <td>-0.634063</td>\n",
       "      <td>-0.316249</td>\n",
       "      <td>-1.049479</td>\n",
       "      <td>1.843692</td>\n",
       "      <td>1.129464</td>\n",
       "      <td>1.145255</td>\n",
       "      <td>-0.981875</td>\n",
       "      <td>0.891988</td>\n",
       "      <td>0.256043</td>\n",
       "      <td>0.581544</td>\n",
       "      <td>1.551307</td>\n",
       "      <td>0.105428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.087232</td>\n",
       "      <td>1.313866</td>\n",
       "      <td>1.036228</td>\n",
       "      <td>-0.268738</td>\n",
       "      <td>0.158572</td>\n",
       "      <td>0.184088</td>\n",
       "      <td>0.382241</td>\n",
       "      <td>-0.901297</td>\n",
       "      <td>0.681738</td>\n",
       "      <td>-0.241413</td>\n",
       "      <td>0.318304</td>\n",
       "      <td>1.282942</td>\n",
       "      <td>0.073583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.876275</td>\n",
       "      <td>-0.427600</td>\n",
       "      <td>-0.023821</td>\n",
       "      <td>-0.869308</td>\n",
       "      <td>0.088358</td>\n",
       "      <td>0.504554</td>\n",
       "      <td>0.854105</td>\n",
       "      <td>-0.740141</td>\n",
       "      <td>0.173634</td>\n",
       "      <td>-0.544212</td>\n",
       "      <td>0.669291</td>\n",
       "      <td>1.960915</td>\n",
       "      <td>0.917474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.186053</td>\n",
       "      <td>-0.660993</td>\n",
       "      <td>0.561033</td>\n",
       "      <td>-0.508966</td>\n",
       "      <td>-0.332922</td>\n",
       "      <td>0.296251</td>\n",
       "      <td>0.342082</td>\n",
       "      <td>-0.820719</td>\n",
       "      <td>-0.229346</td>\n",
       "      <td>-0.487978</td>\n",
       "      <td>0.581544</td>\n",
       "      <td>1.438311</td>\n",
       "      <td>0.853784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.616869</td>\n",
       "      <td>-0.472483</td>\n",
       "      <td>0.890014</td>\n",
       "      <td>0.151661</td>\n",
       "      <td>-0.262708</td>\n",
       "      <td>0.376368</td>\n",
       "      <td>0.583034</td>\n",
       "      <td>-0.659563</td>\n",
       "      <td>0.121071</td>\n",
       "      <td>-0.665332</td>\n",
       "      <td>0.713164</td>\n",
       "      <td>1.706675</td>\n",
       "      <td>0.312420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.061000</td>\n",
       "      <td>-0.257044</td>\n",
       "      <td>3.119772</td>\n",
       "      <td>1.653086</td>\n",
       "      <td>1.703265</td>\n",
       "      <td>0.536601</td>\n",
       "      <td>0.653312</td>\n",
       "      <td>0.871420</td>\n",
       "      <td>0.576613</td>\n",
       "      <td>-0.639377</td>\n",
       "      <td>0.757038</td>\n",
       "      <td>0.830961</td>\n",
       "      <td>0.264653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.480990</td>\n",
       "      <td>-0.508390</td>\n",
       "      <td>0.926567</td>\n",
       "      <td>-1.019451</td>\n",
       "      <td>-0.473348</td>\n",
       "      <td>0.889114</td>\n",
       "      <td>0.914343</td>\n",
       "      <td>-0.176095</td>\n",
       "      <td>-0.246867</td>\n",
       "      <td>-0.111642</td>\n",
       "      <td>-0.164303</td>\n",
       "      <td>0.859210</td>\n",
       "      <td>1.426993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.369816</td>\n",
       "      <td>-0.553273</td>\n",
       "      <td>-0.827996</td>\n",
       "      <td>-0.749194</td>\n",
       "      <td>-0.403135</td>\n",
       "      <td>0.168065</td>\n",
       "      <td>0.161368</td>\n",
       "      <td>-0.740141</td>\n",
       "      <td>-0.422075</td>\n",
       "      <td>-0.479326</td>\n",
       "      <td>0.274431</td>\n",
       "      <td>0.223610</td>\n",
       "      <td>1.713598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.073917</td>\n",
       "      <td>-0.391694</td>\n",
       "      <td>1.584529</td>\n",
       "      <td>-0.028510</td>\n",
       "      <td>0.509638</td>\n",
       "      <td>1.049347</td>\n",
       "      <td>0.944462</td>\n",
       "      <td>0.065639</td>\n",
       "      <td>0.296279</td>\n",
       "      <td>-0.241413</td>\n",
       "      <td>1.283518</td>\n",
       "      <td>1.113449</td>\n",
       "      <td>0.535335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.259207</td>\n",
       "      <td>-0.589180</td>\n",
       "      <td>-0.572122</td>\n",
       "      <td>-1.049479</td>\n",
       "      <td>-0.262708</td>\n",
       "      <td>0.568648</td>\n",
       "      <td>0.301923</td>\n",
       "      <td>-0.820719</td>\n",
       "      <td>0.681738</td>\n",
       "      <td>-0.154899</td>\n",
       "      <td>0.362177</td>\n",
       "      <td>1.381813</td>\n",
       "      <td>0.917474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.394521</td>\n",
       "      <td>0.811175</td>\n",
       "      <td>0.049285</td>\n",
       "      <td>0.602088</td>\n",
       "      <td>-0.543562</td>\n",
       "      <td>-0.585031</td>\n",
       "      <td>-1.274305</td>\n",
       "      <td>0.710264</td>\n",
       "      <td>-0.597284</td>\n",
       "      <td>1.454261</td>\n",
       "      <td>-1.787619</td>\n",
       "      <td>-1.400699</td>\n",
       "      <td>-0.308556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.098058</td>\n",
       "      <td>1.403632</td>\n",
       "      <td>-0.023821</td>\n",
       "      <td>0.602088</td>\n",
       "      <td>0.930918</td>\n",
       "      <td>-1.418243</td>\n",
       "      <td>-0.641805</td>\n",
       "      <td>-0.176095</td>\n",
       "      <td>-0.790013</td>\n",
       "      <td>1.878180</td>\n",
       "      <td>-1.699872</td>\n",
       "      <td>-1.810307</td>\n",
       "      <td>-0.627005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.616869</td>\n",
       "      <td>0.703455</td>\n",
       "      <td>0.926567</td>\n",
       "      <td>1.352801</td>\n",
       "      <td>1.633052</td>\n",
       "      <td>-1.434267</td>\n",
       "      <td>-0.461091</td>\n",
       "      <td>-1.143031</td>\n",
       "      <td>-0.597284</td>\n",
       "      <td>1.532124</td>\n",
       "      <td>-1.612125</td>\n",
       "      <td>-1.852681</td>\n",
       "      <td>-0.786230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>-0.260169</td>\n",
       "      <td>0.299507</td>\n",
       "      <td>0.414820</td>\n",
       "      <td>0.752231</td>\n",
       "      <td>0.860705</td>\n",
       "      <td>-1.306080</td>\n",
       "      <td>-0.671924</td>\n",
       "      <td>-0.981875</td>\n",
       "      <td>-0.579763</td>\n",
       "      <td>2.483778</td>\n",
       "      <td>-2.094732</td>\n",
       "      <td>-1.612565</td>\n",
       "      <td>-0.849920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.135116</td>\n",
       "      <td>-0.391694</td>\n",
       "      <td>1.401762</td>\n",
       "      <td>1.803228</td>\n",
       "      <td>1.141558</td>\n",
       "      <td>-0.152402</td>\n",
       "      <td>-0.752242</td>\n",
       "      <td>-0.820719</td>\n",
       "      <td>-0.054137</td>\n",
       "      <td>0.883269</td>\n",
       "      <td>-1.524378</td>\n",
       "      <td>-1.810307</td>\n",
       "      <td>-1.025067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.283348</td>\n",
       "      <td>0.865035</td>\n",
       "      <td>-0.316249</td>\n",
       "      <td>-0.298767</td>\n",
       "      <td>-0.122282</td>\n",
       "      <td>-0.793334</td>\n",
       "      <td>-1.204027</td>\n",
       "      <td>1.999513</td>\n",
       "      <td>0.489009</td>\n",
       "      <td>2.362658</td>\n",
       "      <td>-1.743745</td>\n",
       "      <td>-1.556068</td>\n",
       "      <td>-0.228944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>-0.519575</td>\n",
       "      <td>-0.939268</td>\n",
       "      <td>-0.974210</td>\n",
       "      <td>0.151661</td>\n",
       "      <td>0.228785</td>\n",
       "      <td>-1.306080</td>\n",
       "      <td>-1.455019</td>\n",
       "      <td>1.354888</td>\n",
       "      <td>-0.334471</td>\n",
       "      <td>1.099554</td>\n",
       "      <td>-1.655999</td>\n",
       "      <td>-1.499570</td>\n",
       "      <td>-0.340401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.209232</td>\n",
       "      <td>2.561618</td>\n",
       "      <td>-0.170035</td>\n",
       "      <td>0.752231</td>\n",
       "      <td>-0.473348</td>\n",
       "      <td>-0.889474</td>\n",
       "      <td>-1.404820</td>\n",
       "      <td>1.999513</td>\n",
       "      <td>-0.071658</td>\n",
       "      <td>1.229325</td>\n",
       "      <td>-1.568252</td>\n",
       "      <td>-1.598441</td>\n",
       "      <td>-0.069719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1.036859</td>\n",
       "      <td>1.601118</td>\n",
       "      <td>0.049285</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>-0.754202</td>\n",
       "      <td>-0.793334</td>\n",
       "      <td>-1.204027</td>\n",
       "      <td>0.951998</td>\n",
       "      <td>-0.054137</td>\n",
       "      <td>1.709478</td>\n",
       "      <td>-1.699872</td>\n",
       "      <td>-1.372450</td>\n",
       "      <td>-0.849920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-0.680159</td>\n",
       "      <td>0.622666</td>\n",
       "      <td>0.999674</td>\n",
       "      <td>2.253656</td>\n",
       "      <td>-0.192495</td>\n",
       "      <td>-0.633101</td>\n",
       "      <td>-1.455019</td>\n",
       "      <td>2.160669</td>\n",
       "      <td>-0.790013</td>\n",
       "      <td>1.056297</td>\n",
       "      <td>-1.261138</td>\n",
       "      <td>-1.245330</td>\n",
       "      <td>0.423878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.654492</td>\n",
       "      <td>-0.589180</td>\n",
       "      <td>1.218995</td>\n",
       "      <td>1.653086</td>\n",
       "      <td>-0.122282</td>\n",
       "      <td>0.808997</td>\n",
       "      <td>-0.722123</td>\n",
       "      <td>1.354888</td>\n",
       "      <td>1.943238</td>\n",
       "      <td>3.435432</td>\n",
       "      <td>-1.699872</td>\n",
       "      <td>-0.920468</td>\n",
       "      <td>-0.276711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.592164</td>\n",
       "      <td>-0.598156</td>\n",
       "      <td>0.999674</td>\n",
       "      <td>0.902373</td>\n",
       "      <td>-0.754202</td>\n",
       "      <td>0.488531</td>\n",
       "      <td>-0.932956</td>\n",
       "      <td>1.274310</td>\n",
       "      <td>1.224884</td>\n",
       "      <td>2.894719</td>\n",
       "      <td>-1.699872</td>\n",
       "      <td>-1.174708</td>\n",
       "      <td>-0.404091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-0.791333</td>\n",
       "      <td>1.340796</td>\n",
       "      <td>0.049285</td>\n",
       "      <td>0.451946</td>\n",
       "      <td>-0.824415</td>\n",
       "      <td>0.007832</td>\n",
       "      <td>-1.113670</td>\n",
       "      <td>1.113154</td>\n",
       "      <td>-0.965221</td>\n",
       "      <td>1.121183</td>\n",
       "      <td>-1.743745</td>\n",
       "      <td>-1.457197</td>\n",
       "      <td>-0.722540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.851569</td>\n",
       "      <td>0.829128</td>\n",
       "      <td>0.634140</td>\n",
       "      <td>0.151661</td>\n",
       "      <td>0.509638</td>\n",
       "      <td>-0.745264</td>\n",
       "      <td>-1.475098</td>\n",
       "      <td>1.113154</td>\n",
       "      <td>-1.385721</td>\n",
       "      <td>0.355534</td>\n",
       "      <td>0.011190</td>\n",
       "      <td>-1.118210</td>\n",
       "      <td>-0.213021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>-0.186053</td>\n",
       "      <td>0.838105</td>\n",
       "      <td>0.780354</td>\n",
       "      <td>0.752231</td>\n",
       "      <td>0.439425</td>\n",
       "      <td>-1.033684</td>\n",
       "      <td>-1.434939</td>\n",
       "      <td>1.918935</td>\n",
       "      <td>-1.105388</td>\n",
       "      <td>0.225763</td>\n",
       "      <td>-0.383670</td>\n",
       "      <td>-0.708602</td>\n",
       "      <td>-0.563315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>-0.050174</td>\n",
       "      <td>0.999684</td>\n",
       "      <td>-0.060375</td>\n",
       "      <td>-0.298767</td>\n",
       "      <td>0.439425</td>\n",
       "      <td>-1.450290</td>\n",
       "      <td>-1.334543</td>\n",
       "      <td>0.307374</td>\n",
       "      <td>-1.140430</td>\n",
       "      <td>0.095992</td>\n",
       "      <td>-1.217265</td>\n",
       "      <td>-1.217081</td>\n",
       "      <td>-0.228944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>0.962743</td>\n",
       "      <td>0.380297</td>\n",
       "      <td>-0.243142</td>\n",
       "      <td>0.752231</td>\n",
       "      <td>-0.683988</td>\n",
       "      <td>-1.514383</td>\n",
       "      <td>-1.354622</td>\n",
       "      <td>0.387952</td>\n",
       "      <td>-0.982742</td>\n",
       "      <td>1.956043</td>\n",
       "      <td>-1.129518</td>\n",
       "      <td>-1.315952</td>\n",
       "      <td>-0.420013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.900980</td>\n",
       "      <td>1.816558</td>\n",
       "      <td>-0.389355</td>\n",
       "      <td>0.902373</td>\n",
       "      <td>-0.824415</td>\n",
       "      <td>-1.626547</td>\n",
       "      <td>-1.565455</td>\n",
       "      <td>1.274310</td>\n",
       "      <td>-0.772492</td>\n",
       "      <td>0.675635</td>\n",
       "      <td>-0.778531</td>\n",
       "      <td>-1.217081</td>\n",
       "      <td>-0.722540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.555106</td>\n",
       "      <td>1.224100</td>\n",
       "      <td>0.853460</td>\n",
       "      <td>1.052516</td>\n",
       "      <td>0.790492</td>\n",
       "      <td>-0.953567</td>\n",
       "      <td>-1.113670</td>\n",
       "      <td>0.549108</td>\n",
       "      <td>-0.229346</td>\n",
       "      <td>2.431870</td>\n",
       "      <td>-0.471417</td>\n",
       "      <td>-1.485445</td>\n",
       "      <td>-0.165254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>-0.223111</td>\n",
       "      <td>0.927871</td>\n",
       "      <td>-0.243142</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>-0.824415</td>\n",
       "      <td>-1.306080</td>\n",
       "      <td>-1.374701</td>\n",
       "      <td>0.307374</td>\n",
       "      <td>-1.087867</td>\n",
       "      <td>2.250190</td>\n",
       "      <td>-1.041771</td>\n",
       "      <td>-1.217081</td>\n",
       "      <td>-0.197099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.715690</td>\n",
       "      <td>0.218717</td>\n",
       "      <td>1.182441</td>\n",
       "      <td>1.502943</td>\n",
       "      <td>0.369212</td>\n",
       "      <td>-1.193917</td>\n",
       "      <td>-1.193987</td>\n",
       "      <td>0.226796</td>\n",
       "      <td>-0.089179</td>\n",
       "      <td>1.558078</td>\n",
       "      <td>-0.954024</td>\n",
       "      <td>-1.146459</td>\n",
       "      <td>0.009893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.493343</td>\n",
       "      <td>2.031997</td>\n",
       "      <td>1.803849</td>\n",
       "      <td>1.653086</td>\n",
       "      <td>0.860705</td>\n",
       "      <td>-0.504914</td>\n",
       "      <td>-1.073511</td>\n",
       "      <td>-0.740141</td>\n",
       "      <td>-0.842575</td>\n",
       "      <td>1.488867</td>\n",
       "      <td>-1.261138</td>\n",
       "      <td>-0.976966</td>\n",
       "      <td>-0.372246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>-0.988975</td>\n",
       "      <td>0.622666</td>\n",
       "      <td>-0.170035</td>\n",
       "      <td>-0.148624</td>\n",
       "      <td>-0.262708</td>\n",
       "      <td>-1.674617</td>\n",
       "      <td>-1.545376</td>\n",
       "      <td>0.307374</td>\n",
       "      <td>-1.508367</td>\n",
       "      <td>0.191157</td>\n",
       "      <td>-1.305011</td>\n",
       "      <td>-1.104086</td>\n",
       "      <td>-0.754385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>-0.284874</td>\n",
       "      <td>0.048161</td>\n",
       "      <td>-0.316249</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>-0.964842</td>\n",
       "      <td>-1.450290</td>\n",
       "      <td>-1.525296</td>\n",
       "      <td>0.951998</td>\n",
       "      <td>-1.666055</td>\n",
       "      <td>2.094465</td>\n",
       "      <td>-1.699872</td>\n",
       "      <td>-1.386574</td>\n",
       "      <td>-0.881765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1.432144</td>\n",
       "      <td>0.155881</td>\n",
       "      <td>0.414820</td>\n",
       "      <td>0.151661</td>\n",
       "      <td>-0.613775</td>\n",
       "      <td>-0.985614</td>\n",
       "      <td>-1.334543</td>\n",
       "      <td>0.629686</td>\n",
       "      <td>-0.614804</td>\n",
       "      <td>2.007951</td>\n",
       "      <td>-1.480505</td>\n",
       "      <td>-1.273579</td>\n",
       "      <td>-0.276711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.876275</td>\n",
       "      <td>2.974543</td>\n",
       "      <td>0.305159</td>\n",
       "      <td>0.301803</td>\n",
       "      <td>-0.332922</td>\n",
       "      <td>-0.985614</td>\n",
       "      <td>-1.424900</td>\n",
       "      <td>1.274310</td>\n",
       "      <td>-0.930179</td>\n",
       "      <td>1.142811</td>\n",
       "      <td>-1.392758</td>\n",
       "      <td>-1.231206</td>\n",
       "      <td>-0.021952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.493343</td>\n",
       "      <td>1.412609</td>\n",
       "      <td>0.414820</td>\n",
       "      <td>1.052516</td>\n",
       "      <td>0.158572</td>\n",
       "      <td>-0.793334</td>\n",
       "      <td>-1.284344</td>\n",
       "      <td>0.549108</td>\n",
       "      <td>-0.316950</td>\n",
       "      <td>0.969783</td>\n",
       "      <td>-1.129518</td>\n",
       "      <td>-1.485445</td>\n",
       "      <td>0.009893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.332758</td>\n",
       "      <td>1.744744</td>\n",
       "      <td>-0.389355</td>\n",
       "      <td>0.151661</td>\n",
       "      <td>1.422412</td>\n",
       "      <td>-1.129824</td>\n",
       "      <td>-1.344582</td>\n",
       "      <td>0.549108</td>\n",
       "      <td>-0.422075</td>\n",
       "      <td>2.224236</td>\n",
       "      <td>-1.612125</td>\n",
       "      <td>-1.485445</td>\n",
       "      <td>0.280575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.209232</td>\n",
       "      <td>0.227694</td>\n",
       "      <td>0.012732</td>\n",
       "      <td>0.151661</td>\n",
       "      <td>1.422412</td>\n",
       "      <td>-1.033684</td>\n",
       "      <td>-1.354622</td>\n",
       "      <td>1.354888</td>\n",
       "      <td>-0.229346</td>\n",
       "      <td>1.834923</td>\n",
       "      <td>-1.568252</td>\n",
       "      <td>-1.400699</td>\n",
       "      <td>0.296498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.395086</td>\n",
       "      <td>1.583165</td>\n",
       "      <td>1.365208</td>\n",
       "      <td>1.502943</td>\n",
       "      <td>-0.262708</td>\n",
       "      <td>-0.392751</td>\n",
       "      <td>-1.274305</td>\n",
       "      <td>1.596623</td>\n",
       "      <td>-0.422075</td>\n",
       "      <td>1.791666</td>\n",
       "      <td>-1.524378</td>\n",
       "      <td>-1.428948</td>\n",
       "      <td>-0.595160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0    1.518613 -0.562250  0.232053 -1.169593  1.913905  0.808997  1.034819   \n",
       "1    0.246290 -0.499413 -0.827996 -2.490847  0.018145  0.568648  0.733629   \n",
       "2    0.196879  0.021231  1.109334 -0.268738  0.088358  0.808997  1.215533   \n",
       "3    1.691550 -0.346811  0.487926 -0.809251  0.930918  2.491446  1.466525   \n",
       "4    0.295700  0.227694  1.840403  0.451946  1.281985  0.808997  0.663351   \n",
       "5    1.481555 -0.517367  0.305159 -1.289707  0.860705  1.562093  1.366128   \n",
       "6    1.716255 -0.418624  0.305159 -1.469878 -0.262708  0.328298  0.492677   \n",
       "7    1.308617 -0.167278  0.890014 -0.569023  1.492625  0.488531  0.482637   \n",
       "8    2.259772 -0.625086 -0.718336 -1.650049 -0.192495  0.808997  0.954502   \n",
       "9    1.061565 -0.885409 -0.352802 -1.049479 -0.122282  1.097417  1.125176   \n",
       "10   1.358028 -0.158301 -0.243142 -0.448909  0.369212  1.049347  1.295850   \n",
       "11   1.382733 -0.768712 -0.170035 -0.809251 -0.332922 -0.152402  0.402320   \n",
       "12   0.925685 -0.544297  0.158946 -1.049479 -0.754202  0.488531  0.733629   \n",
       "13   2.160950 -0.544297  0.085839 -2.430790 -0.613775  1.289697  1.667318   \n",
       "14   1.703902 -0.418624  0.049285 -2.250619  0.158572  1.610163  1.617120   \n",
       "15   0.777454 -0.472483  1.218995 -0.689137  0.860705  0.889114  0.884224   \n",
       "16   1.605081 -0.373741  1.292101  0.151661  1.422412  0.808997  1.115136   \n",
       "17   1.024507 -0.687923  0.926567  0.151661  1.071345  1.049347  1.376168   \n",
       "18   1.469202 -0.669969  0.414820 -0.899337  0.579852  1.610163  1.908270   \n",
       "19   0.789806  0.685502  0.707247 -1.289707  1.141558  0.648764  1.004700   \n",
       "20   1.308617 -0.634063 -0.316249 -1.049479  1.843692  1.129464  1.145255   \n",
       "21  -0.087232  1.313866  1.036228 -0.268738  0.158572  0.184088  0.382241   \n",
       "22   0.876275 -0.427600 -0.023821 -0.869308  0.088358  0.504554  0.854105   \n",
       "23  -0.186053 -0.660993  0.561033 -0.508966 -0.332922  0.296251  0.342082   \n",
       "24   0.616869 -0.472483  0.890014  0.151661 -0.262708  0.376368  0.583034   \n",
       "25   0.061000 -0.257044  3.119772  1.653086  1.703265  0.536601  0.653312   \n",
       "26   0.480990 -0.508390  0.926567 -1.019451 -0.473348  0.889114  0.914343   \n",
       "27   0.369816 -0.553273 -0.827996 -0.749194 -0.403135  0.168065  0.161368   \n",
       "28   1.073917 -0.391694  1.584529 -0.028510  0.509638  1.049347  0.944462   \n",
       "29   1.259207 -0.589180 -0.572122 -1.049479 -0.262708  0.568648  0.301923   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "148  0.394521  0.811175  0.049285  0.602088 -0.543562 -0.585031 -1.274305   \n",
       "149  0.098058  1.403632 -0.023821  0.602088  0.930918 -1.418243 -0.641805   \n",
       "150  0.616869  0.703455  0.926567  1.352801  1.633052 -1.434267 -0.461091   \n",
       "151 -0.260169  0.299507  0.414820  0.752231  0.860705 -1.306080 -0.671924   \n",
       "152  0.135116 -0.391694  1.401762  1.803228  1.141558 -0.152402 -0.752242   \n",
       "153  0.283348  0.865035 -0.316249 -0.298767 -0.122282 -0.793334 -1.204027   \n",
       "154 -0.519575 -0.939268 -0.974210  0.151661  0.228785 -1.306080 -1.455019   \n",
       "155  0.209232  2.561618 -0.170035  0.752231 -0.473348 -0.889474 -1.404820   \n",
       "156  1.036859  1.601118  0.049285  0.001518 -0.754202 -0.793334 -1.204027   \n",
       "157 -0.680159  0.622666  0.999674  2.253656 -0.192495 -0.633101 -1.455019   \n",
       "158  1.654492 -0.589180  1.218995  1.653086 -0.122282  0.808997 -0.722123   \n",
       "159  0.592164 -0.598156  0.999674  0.902373 -0.754202  0.488531 -0.932956   \n",
       "160 -0.791333  1.340796  0.049285  0.451946 -0.824415  0.007832 -1.113670   \n",
       "161  0.851569  0.829128  0.634140  0.151661  0.509638 -0.745264 -1.475098   \n",
       "162 -0.186053  0.838105  0.780354  0.752231  0.439425 -1.033684 -1.434939   \n",
       "163 -0.050174  0.999684 -0.060375 -0.298767  0.439425 -1.450290 -1.334543   \n",
       "164  0.962743  0.380297 -0.243142  0.752231 -0.683988 -1.514383 -1.354622   \n",
       "165  0.900980  1.816558 -0.389355  0.902373 -0.824415 -1.626547 -1.565455   \n",
       "166  0.555106  1.224100  0.853460  1.052516  0.790492 -0.953567 -1.113670   \n",
       "167 -0.223111  0.927871 -0.243142  0.001518 -0.824415 -1.306080 -1.374701   \n",
       "168  0.715690  0.218717  1.182441  1.502943  0.369212 -1.193917 -1.193987   \n",
       "169  0.493343  2.031997  1.803849  1.653086  0.860705 -0.504914 -1.073511   \n",
       "170 -0.988975  0.622666 -0.170035 -0.148624 -0.262708 -1.674617 -1.545376   \n",
       "171 -0.284874  0.048161 -0.316249  0.001518 -0.964842 -1.450290 -1.525296   \n",
       "172  1.432144  0.155881  0.414820  0.151661 -0.613775 -0.985614 -1.334543   \n",
       "173  0.876275  2.974543  0.305159  0.301803 -0.332922 -0.985614 -1.424900   \n",
       "174  0.493343  1.412609  0.414820  1.052516  0.158572 -0.793334 -1.284344   \n",
       "175  0.332758  1.744744 -0.389355  0.151661  1.422412 -1.129824 -1.344582   \n",
       "176  0.209232  0.227694  0.012732  0.151661  1.422412 -1.033684 -1.354622   \n",
       "177  1.395086  1.583165  1.365208  1.502943 -0.262708 -0.392751 -1.274305   \n",
       "\n",
       "           7         8         9         10        11        12  \n",
       "0   -0.659563  1.224884  0.251717  0.362177  1.847920  1.013009  \n",
       "1   -0.820719 -0.544721 -0.293321  0.406051  1.113449  0.965242  \n",
       "2   -0.498407  2.135968  0.269020  0.318304  0.788587  1.395148  \n",
       "3   -0.981875  1.032155  1.186068 -0.427544  1.184071  2.334574  \n",
       "4    0.226796  0.401404 -0.319276  0.362177  0.449601 -0.037874  \n",
       "5   -0.176095  0.664217  0.731870  0.406051  0.336606  2.239039  \n",
       "6   -0.498407  0.681738  0.083015  0.274431  1.367689  1.729520  \n",
       "7   -0.417829 -0.597284 -0.003499  0.449924  1.367689  1.745442  \n",
       "8   -0.578985  0.681738  0.061386  0.537671  0.336606  0.949319  \n",
       "9   -1.143031  0.453967  0.935177  0.230557  1.325316  0.949319  \n",
       "10  -1.143031  1.382572  0.299300  1.283518  0.788587  2.430109  \n",
       "11  -0.820719 -0.036617 -0.025128  0.932531  0.294232  1.697675  \n",
       "12  -0.578985  0.383884  0.234414  0.844785  0.407228  1.825055  \n",
       "13   0.549108  2.135968  0.147900  1.283518  0.167113  1.283691  \n",
       "14  -0.578985  2.398780  1.056297  1.064151  0.548472  2.547935  \n",
       "15  -0.498407 -0.229346  0.969783  1.415139  0.378979  1.793210  \n",
       "16  -0.256673  0.664217  0.493956  0.493797  0.054117  1.697675  \n",
       "17   0.307374  0.226196  0.666984  0.757038 -0.058878  1.220001  \n",
       "18  -0.337251  0.471488  1.575381  1.195772  0.294232  2.971473  \n",
       "19  -1.545922  0.121071  0.018129  0.011190  1.056952  0.312420  \n",
       "20  -0.981875  0.891988  0.256043  0.581544  1.551307  0.105428  \n",
       "21  -0.901297  0.681738 -0.241413  0.318304  1.282942  0.073583  \n",
       "22  -0.740141  0.173634 -0.544212  0.669291  1.960915  0.917474  \n",
       "23  -0.820719 -0.229346 -0.487978  0.581544  1.438311  0.853784  \n",
       "24  -0.659563  0.121071 -0.665332  0.713164  1.706675  0.312420  \n",
       "25   0.871420  0.576613 -0.639377  0.757038  0.830961  0.264653  \n",
       "26  -0.176095 -0.246867 -0.111642 -0.164303  0.859210  1.426993  \n",
       "27  -0.740141 -0.422075 -0.479326  0.274431  0.223610  1.713598  \n",
       "28   0.065639  0.296279 -0.241413  1.283518  1.113449  0.535335  \n",
       "29  -0.820719  0.681738 -0.154899  0.362177  1.381813  0.917474  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "148  0.710264 -0.597284  1.454261 -1.787619 -1.400699 -0.308556  \n",
       "149 -0.176095 -0.790013  1.878180 -1.699872 -1.810307 -0.627005  \n",
       "150 -1.143031 -0.597284  1.532124 -1.612125 -1.852681 -0.786230  \n",
       "151 -0.981875 -0.579763  2.483778 -2.094732 -1.612565 -0.849920  \n",
       "152 -0.820719 -0.054137  0.883269 -1.524378 -1.810307 -1.025067  \n",
       "153  1.999513  0.489009  2.362658 -1.743745 -1.556068 -0.228944  \n",
       "154  1.354888 -0.334471  1.099554 -1.655999 -1.499570 -0.340401  \n",
       "155  1.999513 -0.071658  1.229325 -1.568252 -1.598441 -0.069719  \n",
       "156  0.951998 -0.054137  1.709478 -1.699872 -1.372450 -0.849920  \n",
       "157  2.160669 -0.790013  1.056297 -1.261138 -1.245330  0.423878  \n",
       "158  1.354888  1.943238  3.435432 -1.699872 -0.920468 -0.276711  \n",
       "159  1.274310  1.224884  2.894719 -1.699872 -1.174708 -0.404091  \n",
       "160  1.113154 -0.965221  1.121183 -1.743745 -1.457197 -0.722540  \n",
       "161  1.113154 -1.385721  0.355534  0.011190 -1.118210 -0.213021  \n",
       "162  1.918935 -1.105388  0.225763 -0.383670 -0.708602 -0.563315  \n",
       "163  0.307374 -1.140430  0.095992 -1.217265 -1.217081 -0.228944  \n",
       "164  0.387952 -0.982742  1.956043 -1.129518 -1.315952 -0.420013  \n",
       "165  1.274310 -0.772492  0.675635 -0.778531 -1.217081 -0.722540  \n",
       "166  0.549108 -0.229346  2.431870 -0.471417 -1.485445 -0.165254  \n",
       "167  0.307374 -1.087867  2.250190 -1.041771 -1.217081 -0.197099  \n",
       "168  0.226796 -0.089179  1.558078 -0.954024 -1.146459  0.009893  \n",
       "169 -0.740141 -0.842575  1.488867 -1.261138 -0.976966 -0.372246  \n",
       "170  0.307374 -1.508367  0.191157 -1.305011 -1.104086 -0.754385  \n",
       "171  0.951998 -1.666055  2.094465 -1.699872 -1.386574 -0.881765  \n",
       "172  0.629686 -0.614804  2.007951 -1.480505 -1.273579 -0.276711  \n",
       "173  1.274310 -0.930179  1.142811 -1.392758 -1.231206 -0.021952  \n",
       "174  0.549108 -0.316950  0.969783 -1.129518 -1.485445  0.009893  \n",
       "175  0.549108 -0.422075  2.224236 -1.612125 -1.485445  0.280575  \n",
       "176  1.354888 -0.229346  1.834923 -1.568252 -1.400699  0.296498  \n",
       "177  1.596623 -0.422075  1.791666 -1.524378 -1.428948 -0.595160  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=3)  # 데이터를 3개의 클러스터로 묶음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=3, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = AffinityPropagation(preference=-200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AffinityPropagation(affinity='euclidean', convergence_iter=15, copy=True,\n",
       "          damping=0.5, max_iter=200, preference=-200, verbose=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 1, 1, 1,\n",
       "       1, 1, 2, 1, 2, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = MeanShift(bandwidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeanShift(bandwidth=3, bin_seeding=False, cluster_all=True, min_bin_freq=1,\n",
       "     n_jobs=None, seeds=None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 2, 1, 0, 0, 5, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 2, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       9, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 8, 4, 4, 4, 0, 0, 0, 0, 4, 7, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SpectralClustering(n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2,\n",
       "       2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 0, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.fit_predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = AgglomerativeClustering(n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 1, 0, 0, 0, 2,\n",
       "       2, 0, 1, 0, 1, 2, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1], dtype=int64)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac.fit_predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DBSCAN(eps=3, min_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0, -1,  0,  0,  0, -1,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0, -1,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0, -1, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0], dtype=int64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.fit_predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.20.3'"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_km = km.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_ap = ap.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eupho\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\cluster\\unsupervised.py:342: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  score = (intra_dists[:, None] + intra_dists) / centroid_distances\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.389187977718165"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "davies_bouldin_score(x, labels_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eupho\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\cluster\\unsupervised.py:342: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  score = (intra_dists[:, None] + intra_dists) / centroid_distances\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4523177938566059"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "davies_bouldin_score(x, labels_ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2848589191898987"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhouette_score(x, labels_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2511804643887535"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "silhouette_score(x, labels_ap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
